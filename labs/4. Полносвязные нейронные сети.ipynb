{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13d68de6",
   "metadata": {
    "id": "13d68de6"
   },
   "source": [
    "# Лабораторная работа 4. Полносвязные нейронные сети (многослойный персептрон). Решение задач регрессии и классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9f92923",
   "metadata": {
    "id": "e9f92923"
   },
   "source": [
    "## Искусственные нейроны"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d1a07e2",
   "metadata": {
    "id": "8d1a07e2"
   },
   "source": [
    "Искусственными нейронными сетями (чаще - просто нейронными сетями) называются модели машинного обучения, в основе функционирования которых лежат <b>принципы работы биологических нейронов</b> в человеческом мозге. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8517f9",
   "metadata": {
    "id": "fa8517f9"
   },
   "source": [
    "Идея, лежащая в основе нейронных сетей, очень простая: каждый биологический нейрон имеет несколько входов (дендритов), на основе информации с которых формируется выходной сигнал, который с помощью выхода (аксона) передается далее к органам человеческого (и не только) организма. В 1943 году У. Маккалок и У. Питтс предложили идею искусственного нейрона."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea8fb4c",
   "metadata": {
    "id": "7ea8fb4c"
   },
   "source": [
    "![](https://upload.wikimedia.org/wikipedia/ru/thumb/b/ba/Single_layer_perceptron.png/270px-Single_layer_perceptron.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f99850",
   "metadata": {
    "id": "38f99850"
   },
   "source": [
    "Искусственный нейрон также имеет дендриты и аксон. Математически, здесь на вход нейрона подается некоторый вектор из чисел $x$. При этом каждый дендрит имеет свой вес $w$. Значение нейрона $h$ вычисляется как $h=wx^T$, если в векторной форме. А если в скалярной, то речь идет о простом перемножении компонент входного вектора на соответствующие веса связей и последующее суммирование."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1e50bf",
   "metadata": {
    "id": "7c1e50bf"
   },
   "source": [
    "Заметим, что такой нейрон полностью эквивалентен линейному регрессору, а это значит, что он может находить в данных исключительно линейные зависимости. Чтобы такого не было придумали передавать аксону не $h$, а $f(h)$, где $f$ - нелинейная функция, называемая <b>функцией активации</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f41ff97",
   "metadata": {
    "id": "7f41ff97"
   },
   "source": [
    "Функции активации способны управлять множеством значений нейрона. Ниже приведены некоторые функции активации."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf033d03",
   "metadata": {
    "id": "bf033d03"
   },
   "source": [
    "![](https://programforyou.ru/images/useful/cnn/part0/activations.png?v=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67a4f37",
   "metadata": {
    "id": "d67a4f37"
   },
   "source": [
    "## Полносвязные нейронные сети. Получение предсказаний"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a2cce9",
   "metadata": {
    "id": "52a2cce9"
   },
   "source": [
    "Со временем идея искусственных нейронов была обобщена. Появились модели, в которых уже присутствовало несколько взаимосвязанных между собой нейронов. Исторически первым прикладным обобщением сетей из искусственных нейронов является <b>многослойный персептрон</b>. Его концепция была предложена Ф. Розенблатом в 1958 году. Однако персептрон Розенблата имел всего три слоя. Мы же будем рассматривать обобщенную модель."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d046b4bb",
   "metadata": {
    "id": "d046b4bb"
   },
   "source": [
    "![](https://neerc.ifmo.ru/wiki/images/thumb/6/63/Multi-layer-neural-net-scheme.png/500px-Multi-layer-neural-net-scheme.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea7d5d8",
   "metadata": {
    "id": "6ea7d5d8"
   },
   "source": [
    "Представленая выше нейронная сеть (многослойный персептрон) называется <b>полносвязной</b>. Это означает, что каждый нейрон текущего слоя связан с каждым нейроном предыдущего слоя. Если скрытых нейронов больше чем один, то такая сеть называется <b>глубокой</b>. Обучение глубоких нейронных сетей называется глубоким обучением."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4485ea9e",
   "metadata": {
    "id": "4485ea9e"
   },
   "source": [
    "В сети выделяют входной слой (нейроны, на которых просто размещается вектор входных значений), скрытые слои (у каждого слоя своя функция активации, которую используют все нейроны) и выходной слой (функция активации выходного слоя отображает значения суммы в требуемое множество значений). Вы, наверное, догадались, что в случае регрессии функция активации выходного слоя, как правило, не ограничивает значения нейронов (то есть может вообще не применяться), может отображать значения нейрона в положительное число (например, relu). В случае классификации в большинстве случаев используются функции активации sigmoid и softmax. Как именно они применяются вы увидите на практике ниже."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3c0722",
   "metadata": {
    "id": "ad3c0722"
   },
   "source": [
    "Получение предсказаний с помощью нейронной сети - это <b>процесс последовательного выполнения матричного умножения с последующим поэлементным применением функции активации к получившемуся вектору<b>. Не верите? давайте это увидим."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5dc34f6",
   "metadata": {
    "id": "d5dc34f6"
   },
   "source": [
    "Каждому слою сети (кроме входного) соответствует матрица обучаемых параметров. Пусть мы рассматриваем первых скрытый слой, обозначим количество его нейронов за $m$. Обозначим количество нейронов предыдущего слоя (входного) за $n$. Тогда матрица весов слоя $W$ будет иметь размерность $m{\\times}n$. Элемент $w_{ij}$ - вес связи $i$ нейрона текущего слоя с $j$ нейроном предыдущего."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442c1622",
   "metadata": {
    "id": "442c1622"
   },
   "source": [
    "Также каждому слою соответствует собственный вектор $b$ - это значение сдвига. Количество элементов вектора b соответствует количеству нейронов текущего слоя. Значения нейронов текущего слоя $h$ вычисляется как $h=Wx+b$. Выходное значение нейронов вычисляется как $f(h)$, где $f$ - функция активации текущего слоя."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63a2d7a",
   "metadata": {
    "id": "b63a2d7a"
   },
   "source": [
    "Как вы видите, получить предсказания очень просто. Изначально значения W и b каждого слоя инициализируются случайным образом. Вы понимаете, что для получения адекватных предсказаний нам необходимо выполнить обучение, то есть <b>найти значения W и b для каждого слоя сети, которые позволят минимизировать функцию ошибки</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7395af",
   "metadata": {
    "id": "4c7395af"
   },
   "source": [
    "## Обучение полносвязных нейронных сетей. Алгоритм обратного распространения ошибки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431697ea",
   "metadata": {
    "id": "431697ea"
   },
   "source": [
    "Обучение нейронной сети производится с использованием подходов, в основе которых лежит градиентный спуск. В самом простом случае - это обычный, уже знакомый нам, метод наискорейшего спуска. Но вот задача - все эти методы требуют расчета градиента функции ошибки. А как нам посчитать градиент функции ошибки при использовании нейронной сети? Оказывается, что в этом случае мы не можем просто взять и посчитать сразу весь градиент. Вместо этого, мы можем вычислить его по отдельным частям. Алгоритм вычисления градиента, используемый при обучении нейронных сетей, получил название <b>метод обратного распространения ошибки (backpropagation)</b>. Понимание его работы - это основа вашего понимания работы нейронных сетей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376a01ba",
   "metadata": {
    "id": "376a01ba"
   },
   "source": [
    "Суть метода обратного распространения ошибки заключается в том, что мы после получения конечных предсказаний начинаем идти назад (от последнего слоя к первому) и последовательно вычислять части градиента. Как вы, наверное, догадались, обучаемыми параметрами у нас являются $W$ и $b$ для каждого слоя. Мы двигаемся начиная с последнего слоя и последовательно вычисляем эти градиенты."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a241e8a",
   "metadata": {
    "id": "7a241e8a"
   },
   "source": [
    "Для того, чтобы нам удобно было все это понять, давайте каждый слой разобьем еще на два слоя. Для простоты сделаем так, что вся сеть имеет только входной слой и выходной (выходной разбит на два отдельных слоя)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4a7d99",
   "metadata": {
    "id": "eb4a7d99"
   },
   "source": [
    "![](https://i.vgy.me/S1IeLk.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e36a3e",
   "metadata": {
    "id": "a8e36a3e"
   },
   "source": [
    "Мы видим, что любую нейронную сеть таким образом можно разбить на большее количество слоев, если каждый слой с функцией активации разбить на два слоя. Представить, что на первом выполняется суммирование произведений (умножение матрицы на вектор и добавление сдвига), а на втором - поэлементное применение функции активации. Продолжая подобные рассуждения, мы придем к тому, что любая полносвязная сеть может быть представлена как набор последовательных компонентов, каждый из которых можно рассматривать как функцию."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11839a14",
   "metadata": {
    "id": "11839a14"
   },
   "source": [
    "![](https://i.vgy.me/7vWpIw.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c3a7c6",
   "metadata": {
    "id": "05c3a7c6"
   },
   "source": [
    "Каждый такой компонент берет входные данные и преобразует их в выходные (в случае полносвязной нейронной сети компонент либо выполняет линейное преобразование, либо применяет функцию активации). Входные данные текущего блока являются выходными данными предыдущего. Но посмотрите, а что представляют собой тогда выходные данные последнего компонента с математической точки зрения? Это ни что иное, как результат применения <b>сложной функции</b> к входным данным. В данном случае, $y_3=f_3(f_2(f_1(x_1)))$. А теперь давайте вспомним, что каждый эти компоненты содержат обучаемые параметры $W$ и $b$. В данном случае у нас есть $W_1$ и $b_1$, а также $W_3$ и $b_3$ (второй компонент не содержит обучающих параметров, поскольку отвечает за просто поэлементное применение функции активации)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be6d5ee",
   "metadata": {
    "id": "6be6d5ee"
   },
   "source": [
    "Но мы с вами ранее сказали о том, что градиент вычисляется частично и по каждому множеству обучаемых параметров, так? Да, все именно так. Мат. анализ предоставляет нам замечательный инструмент для вычисления производных сложной функции - <b>цепное правило (chain rule)</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7594ccb",
   "metadata": {
    "id": "f7594ccb"
   },
   "source": [
    "Суть цепного правила вы помните со школы: если $y=y(g(x))$, то ${\\frac{dy}{dx}}={\\frac{dy}{dg}}{\\frac{dg}{dx}}$. То же самое работает и в нашем случае. Каждый компонент использует значения частных производных функции потерь по своему выходу для непосредственного вычисления частных производных функции потерь по $W$ и $b$, а также передает предыдущему компоненту вычисленные значения производной функии потерь по своему входу. Далее компонент с использованием оптимизатора делает шаг градиентного спуска (обновляются значения весов $W$ и $b$). <b>Обращаю внимание: обновление весов выполняется ПОСЛЕ вычисления частных производных по весам</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dea9a2",
   "metadata": {
    "id": "82dea9a2"
   },
   "source": [
    "![sejsej](https://i.vgy.me/m5KKFF.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fd14a4",
   "metadata": {
    "id": "98fd14a4"
   },
   "source": [
    "Итак, пусть у нас задана функция потерь. Для регрессии и бинарной классификации можно использовать модифицированную MSE: $E={\\frac{1}{2}}(y-\\hat{y})^2$. Мы хотим ее минимизировать. Ранее мы буквой $L$ обозначали функцию потерь, а при работе с нейронными сетями устоялось обозначение $E$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca869d1e",
   "metadata": {
    "id": "ca869d1e"
   },
   "source": [
    "Осталось разобраться, по каким формулам вычисляются части градиента в каждом компоненте. Мы знаем, что в каждом компоненте вычисляется $\\frac{\\partial{E}}{\\partial{x}}$. В некоторых компонентах вычисляются $\\frac{\\partial{E}}{\\partial{W}}$ и $\\frac{\\partial{E}}{\\partial{b}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "733f597a",
   "metadata": {
    "id": "733f597a"
   },
   "source": [
    "Запишем формулы:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad6e1a1",
   "metadata": {
    "id": "dad6e1a1"
   },
   "source": [
    "$\\frac{\\partial{E}}{\\partial{W}}$ = $\\frac{\\partial{E}}{\\partial{y}}x^T$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe2984a",
   "metadata": {
    "id": "abe2984a"
   },
   "source": [
    "$\\frac{\\partial{E}}{\\partial{b}}$ = $\\frac{\\partial{E}}{\\partial{y}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc66a9d5",
   "metadata": {
    "id": "dc66a9d5"
   },
   "source": [
    "Частные производные функции потерь по входу вычисляются по разному, в зависимости от назначения компонента. Если это компонент, реализующий линейное преобразование ($Wx+b$), то $\\frac{\\partial{E}}{\\partial{x}} = W^T\\frac{\\partial{E}}{\\partial{y}} $. Если это компонент, применяющий функцию активации $f$ (sigmoid, tanh, relu), то $\\frac{\\partial{E}}{\\partial{x}} = \\frac{\\partial{E}}{\\partial{y}}\\odot f'(x) $. $\\odot$ - это поэлементное произведение векторов (произведение Адамара). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122831c5",
   "metadata": {
    "id": "122831c5"
   },
   "source": [
    "Можно увидеть, что все функции активации слоев обязаны быть дифференцируемыми. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0382aa47",
   "metadata": {
    "id": "0382aa47"
   },
   "source": [
    "При решении задач классификации (в общем случае, когда количество классов больше двух), как правило, применяется функция потерь перекрестная энтропия (при бинарной классификации применяется ее частный случай - бинарная перекрестная кросэнтропия). Выглядит она следующим образом:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0701bb5a",
   "metadata": {
    "id": "0701bb5a"
   },
   "source": [
    "Общий случай: $E = -\\sum_{k}^{s}{{y_k}ln{\\hat{y_k}}}$. Здесь s - количество классов. При использовании такой функции потерь, предполагается, что целевой признак размечен (например, для случая двух классов) как [1, 0]. Это оначает, что объект относится к 0 классу. Предположим, модель предсказала ответ [0,36, 0,64]. Она ошиблась. Можно посчитать значение перекрестной энтропии и обновить веса."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ea437c",
   "metadata": {
    "id": "d8ea437c"
   },
   "source": [
    "Как вы видите, использование перекрестной энтропии требует, чтобы сумма значений нейронов была единица и все числа были положительными. Для получения такого результата на произвольном слое с нейронами используется функция softmax. Ее можно назвать функцией активации, однако при использовании softmax $\\frac{\\partial{E}}{\\partial{x}}$ считается по другому. $\\frac{\\partial{E}}{\\partial{x}} = ((1-y^T)y)\\frac{\\partial{E}}{\\partial{y}} $. Подчеркну, что 1 здесь обозначена единичная матрица."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647ebb36",
   "metadata": {
    "id": "647ebb36"
   },
   "source": [
    "Вот и все. Теперь вы можете реализовать собственную полносвязную нейронную сеть. Для облегчения задачи представьте ее в виде компонентов, как это описано выше. Чтобы начать вычисление градиента необходимо начать двигаться от последнего компонента к первому, при этом предварительно посчитать частную производную функции потерь по выходу последнего компонента."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb42973",
   "metadata": {
    "id": "adb42973"
   },
   "source": [
    "## Использование фреймворка TensorFlow и API Keras для построеония нейронных сетей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08b38f0",
   "metadata": {
    "id": "b08b38f0"
   },
   "source": [
    "Мы разобрались, как работают полносвязные нейронные сети. Давайте теперь решим задачи регрессии и классификации с помощью фреймворка TensorFlow. Начнем с загрузки предварительно обработанных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5340d31a",
   "metadata": {
    "id": "5340d31a"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_regression = pd.read_csv(\"../data/regression/apartment_data_preprocessed.csv\")\n",
    "data_classification = pd.read_csv(\"../data/classification/bank_churners_preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d04b7d",
   "metadata": {
    "id": "a0d04b7d"
   },
   "outputs": [],
   "source": [
    "data_regression.drop(columns = [\"Unnamed: 0\"], inplace=True)\n",
    "data_classification.drop(columns = [\"Unnamed: 0\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6bc6d4",
   "metadata": {
    "id": "ef6bc6d4",
    "outputId": "61070045-2298-4c89-e866-2bf53ba5b41b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SalePrice</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>MonthSold</th>\n",
       "      <th>Size(sqf)</th>\n",
       "      <th>Floor</th>\n",
       "      <th>N_Parkinglot(Ground)</th>\n",
       "      <th>N_Parkinglot(Basement)</th>\n",
       "      <th>TimeToBusStop</th>\n",
       "      <th>TimeToSubway</th>\n",
       "      <th>...</th>\n",
       "      <th>c_management_in_trust</th>\n",
       "      <th>c_self_management</th>\n",
       "      <th>c_Bangoge</th>\n",
       "      <th>c_Banwoldang</th>\n",
       "      <th>c_Chil-sung-market</th>\n",
       "      <th>c_Daegu</th>\n",
       "      <th>c_Kyungbuk_uni_hospital</th>\n",
       "      <th>c_Myung-duk</th>\n",
       "      <th>c_Sin-nam</th>\n",
       "      <th>c_no_subway_nearby</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141592</td>\n",
       "      <td>2006</td>\n",
       "      <td>2007</td>\n",
       "      <td>8</td>\n",
       "      <td>814</td>\n",
       "      <td>3</td>\n",
       "      <td>111.0</td>\n",
       "      <td>184.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51327</td>\n",
       "      <td>1985</td>\n",
       "      <td>2007</td>\n",
       "      <td>8</td>\n",
       "      <td>587</td>\n",
       "      <td>8</td>\n",
       "      <td>80.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48672</td>\n",
       "      <td>1985</td>\n",
       "      <td>2007</td>\n",
       "      <td>8</td>\n",
       "      <td>587</td>\n",
       "      <td>6</td>\n",
       "      <td>80.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>380530</td>\n",
       "      <td>2006</td>\n",
       "      <td>2007</td>\n",
       "      <td>8</td>\n",
       "      <td>2056</td>\n",
       "      <td>8</td>\n",
       "      <td>249.0</td>\n",
       "      <td>536.0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>221238</td>\n",
       "      <td>1993</td>\n",
       "      <td>2007</td>\n",
       "      <td>8</td>\n",
       "      <td>1761</td>\n",
       "      <td>3</td>\n",
       "      <td>523.0</td>\n",
       "      <td>536.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SalePrice  YearBuilt  YrSold  MonthSold  Size(sqf)  Floor  \\\n",
       "0     141592       2006    2007          8        814      3   \n",
       "1      51327       1985    2007          8        587      8   \n",
       "2      48672       1985    2007          8        587      6   \n",
       "3     380530       2006    2007          8       2056      8   \n",
       "4     221238       1993    2007          8       1761      3   \n",
       "\n",
       "   N_Parkinglot(Ground)  N_Parkinglot(Basement)  TimeToBusStop  TimeToSubway  \\\n",
       "0                 111.0                   184.0              1             2   \n",
       "1                  80.0                    76.0              2             3   \n",
       "2                  80.0                    76.0              2             3   \n",
       "3                 249.0                   536.0              2             4   \n",
       "4                 523.0                   536.0              2             1   \n",
       "\n",
       "   ...  c_management_in_trust  c_self_management  c_Bangoge  c_Banwoldang  \\\n",
       "0  ...                      1                  0          0             0   \n",
       "1  ...                      0                  1          0             0   \n",
       "2  ...                      0                  1          0             0   \n",
       "3  ...                      1                  0          0             0   \n",
       "4  ...                      1                  0          0             0   \n",
       "\n",
       "   c_Chil-sung-market  c_Daegu  c_Kyungbuk_uni_hospital  c_Myung-duk  \\\n",
       "0                   0        0                        1            0   \n",
       "1                   0        1                        0            0   \n",
       "2                   0        1                        0            0   \n",
       "3                   0        0                        0            0   \n",
       "4                   0        0                        0            1   \n",
       "\n",
       "   c_Sin-nam  c_no_subway_nearby  \n",
       "0          0                   0  \n",
       "1          0                   0  \n",
       "2          0                   0  \n",
       "3          1                   0  \n",
       "4          0                   0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_regression.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df0807a",
   "metadata": {
    "id": "9df0807a",
    "outputId": "6e1a6123-a978-4278-fd47-6834d9096dfb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Attrition_Flag</th>\n",
       "      <th>Customer_Age</th>\n",
       "      <th>Dependent_count</th>\n",
       "      <th>Education_Level</th>\n",
       "      <th>Income_Category</th>\n",
       "      <th>Card_Category</th>\n",
       "      <th>Months_on_book</th>\n",
       "      <th>Total_Relationship_Count</th>\n",
       "      <th>Months_Inactive_12_mon</th>\n",
       "      <th>Contacts_Count_12_mon</th>\n",
       "      <th>...</th>\n",
       "      <th>Total_Trans_Amt</th>\n",
       "      <th>Total_Trans_Ct</th>\n",
       "      <th>Total_Ct_Chng_Q4_Q1</th>\n",
       "      <th>Avg_Utilization_Ratio</th>\n",
       "      <th>c_F</th>\n",
       "      <th>c_M</th>\n",
       "      <th>c_Divorced</th>\n",
       "      <th>c_Married</th>\n",
       "      <th>c_Single</th>\n",
       "      <th>c_Unknown</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>1144</td>\n",
       "      <td>42</td>\n",
       "      <td>1.625</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>44</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1291</td>\n",
       "      <td>33</td>\n",
       "      <td>3.714</td>\n",
       "      <td>0.105</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1887</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1171</td>\n",
       "      <td>20</td>\n",
       "      <td>2.333</td>\n",
       "      <td>0.760</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>816</td>\n",
       "      <td>28</td>\n",
       "      <td>2.500</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Attrition_Flag  Customer_Age  Dependent_count  Education_Level  \\\n",
       "0               0            45                3                2   \n",
       "1               0            49                5                5   \n",
       "2               0            51                3                5   \n",
       "3               0            40                4                2   \n",
       "4               0            40                3                1   \n",
       "\n",
       "   Income_Category  Card_Category  Months_on_book  Total_Relationship_Count  \\\n",
       "0                3              0              39                         5   \n",
       "1                1              0              44                         6   \n",
       "2                4              0              36                         4   \n",
       "3                1              0              34                         3   \n",
       "4                3              0              21                         5   \n",
       "\n",
       "   Months_Inactive_12_mon  Contacts_Count_12_mon  ...  Total_Trans_Amt  \\\n",
       "0                       1                      3  ...             1144   \n",
       "1                       1                      2  ...             1291   \n",
       "2                       1                      0  ...             1887   \n",
       "3                       4                      1  ...             1171   \n",
       "4                       1                      0  ...              816   \n",
       "\n",
       "   Total_Trans_Ct  Total_Ct_Chng_Q4_Q1  Avg_Utilization_Ratio  c_F  c_M  \\\n",
       "0              42                1.625                  0.061    0    1   \n",
       "1              33                3.714                  0.105    1    0   \n",
       "2              20                2.333                  0.000    0    1   \n",
       "3              20                2.333                  0.760    1    0   \n",
       "4              28                2.500                  0.000    0    1   \n",
       "\n",
       "   c_Divorced  c_Married  c_Single  c_Unknown  \n",
       "0           0          1         0          0  \n",
       "1           0          0         1          0  \n",
       "2           0          1         0          0  \n",
       "3           0          0         0          1  \n",
       "4           0          1         0          0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_classification.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc58fb63",
   "metadata": {
    "id": "dc58fb63"
   },
   "outputs": [],
   "source": [
    "y_regression = data_regression[\"SalePrice\"]\n",
    "X_regression = data_regression.drop(columns = ['SalePrice'])\n",
    "y_classification = data_classification['Attrition_Flag']\n",
    "X_classification = data_classification.drop(columns = ['Attrition_Flag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5cf5839",
   "metadata": {
    "id": "f5cf5839"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_regression_train, X_regression_test, y_regression_train, y_regression_test = train_test_split(X_regression,\n",
    "                                                                                                y_regression,\n",
    "                                                                                                test_size=0.2)\n",
    "X_classification_train, X_classification_test, y_classification_train, y_classification_test = train_test_split(X_classification,\n",
    "                                                                                                                y_classification,\n",
    "                                                                                                                stratify=y_classification,\n",
    "                                                                                                                test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b84f4fc",
   "metadata": {
    "id": "9b84f4fc"
   },
   "source": [
    "Импортируем метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fda21ed2",
   "metadata": {
    "id": "fda21ed2"
   },
   "outputs": [],
   "source": [
    "# для оценки качества решения задачи регрессии\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "# для оценки качества решения задачи классификации\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "078d1a1c",
   "metadata": {
    "id": "078d1a1c"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f49610a3",
   "metadata": {
    "id": "f49610a3"
   },
   "source": [
    "### Регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e563d4d",
   "metadata": {
    "id": "0e563d4d"
   },
   "source": [
    "Создаем полносвязную нейронную сеть для решения задачи регрессии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c73d33",
   "metadata": {
    "id": "b3c73d33"
   },
   "outputs": [],
   "source": [
    "# создаем модель, как набор последовательных слоев\n",
    "model_regression = tf.keras.Sequential(\n",
    "    [\n",
    "        # Dense - полносвязный слой (каждый нейрон следующего слоя связан со всеми нейронами предыдущего)\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(40,)),\n",
    "        # на втором скрытом слое будет 32 нейрона\n",
    "        tf.keras.layers.Dense(32, activation=\"linear\"),\n",
    "        # Dropout позволяет внести фактор случайности - при обучении часть нейронов будет отключаться\n",
    "        # каждый нейрон, в данном случае, будет отключаться с вероятностью 0.1\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.1),\n",
    "        # на выходе один нейрон, функция активации не применяется\n",
    "        tf.keras.layers.Dense(1, activation=\"linear\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af49e8d0",
   "metadata": {
    "id": "af49e8d0",
    "outputId": "eaee9795-f3d3-4e99-d4f3-f218f0440c11"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 64)                2624      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,249\n",
      "Trainable params: 5,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# посмотрим, какая сеть у нас получилась\n",
    "model_regression.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04c118e",
   "metadata": {
    "id": "f04c118e"
   },
   "source": [
    "Видим количество обучаемых параметров каждого слоя и общее количество обучаемых параметров. Перед использованием модель необходимо скомпилировать, при этом указывается оптимизатор, скорость обучения (можно представлять как величину шага в методе градиентного спуска), функция потерь и метрики, которые мы хотим (при желании) вычислять в будущем методом evaluate()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ebc13f",
   "metadata": {
    "id": "11ebc13f"
   },
   "outputs": [],
   "source": [
    "# компилируем\n",
    "model_regression.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d03d027",
   "metadata": {
    "id": "5d03d027",
    "outputId": "66fc9b4f-897f-4f1d-b43d-0699ba361f00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "148/148 [==============================] - 1s 1ms/step - loss: 18677094400.0000\n",
      "Epoch 2/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 5956613120.0000\n",
      "Epoch 3/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 5302459392.0000\n",
      "Epoch 4/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 5173764608.0000\n",
      "Epoch 5/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 5024999936.0000\n",
      "Epoch 6/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 4719655936.0000\n",
      "Epoch 7/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 4645587456.0000\n",
      "Epoch 8/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 4634443264.0000\n",
      "Epoch 9/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 4532004864.0000\n",
      "Epoch 10/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 4173457920.0000\n",
      "Epoch 11/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 4276416000.0000\n",
      "Epoch 12/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 4374330368.0000\n",
      "Epoch 13/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 4385856512.0000\n",
      "Epoch 14/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 4252396800.0000\n",
      "Epoch 15/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 4199605504.0000\n",
      "Epoch 16/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 4403289600.0000\n",
      "Epoch 17/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 4192039424.0000\n",
      "Epoch 18/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 4135811584.0000\n",
      "Epoch 19/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 4035171840.0000\n",
      "Epoch 20/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 3964751872.0000\n",
      "Epoch 21/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 3939002112.0000\n",
      "Epoch 22/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 3839074048.0000\n",
      "Epoch 23/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 3839807744.0000\n",
      "Epoch 24/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 3713281280.0000\n",
      "Epoch 25/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 3728565760.0000\n",
      "Epoch 26/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 3852269824.0000\n",
      "Epoch 27/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 3693128704.0000\n",
      "Epoch 28/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 3828483584.0000\n",
      "Epoch 29/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 3818676992.0000\n",
      "Epoch 30/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 3677117184.0000\n",
      "Epoch 31/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 3871500032.0000\n",
      "Epoch 32/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 3598656256.0000\n",
      "Epoch 33/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 3614639872.0000\n",
      "Epoch 34/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 3749658368.0000\n",
      "Epoch 35/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 3680359168.0000\n",
      "Epoch 36/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 3564896000.0000\n",
      "Epoch 37/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 3581931520.0000\n",
      "Epoch 38/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 3631480064.0000\n",
      "Epoch 39/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 3530358272.0000\n",
      "Epoch 40/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 3542114816.0000\n",
      "Epoch 41/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 3609455616.0000\n",
      "Epoch 42/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 3496535296.0000\n",
      "Epoch 43/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 3556663296.0000\n",
      "Epoch 44/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 3478364672.0000\n",
      "Epoch 45/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 3352423680.0000\n",
      "Epoch 46/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 3440696832.0000\n",
      "Epoch 47/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 3313053952.0000\n",
      "Epoch 48/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 3312765184.0000\n",
      "Epoch 49/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 3432930816.0000\n",
      "Epoch 50/50\n",
      "148/148 [==============================] - 0s 1ms/step - loss: 3333359104.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2666b0d42e0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# обучаем, 10 эпох означает 10 проходов по обучающей выборке\n",
    "model_regression.fit(X_regression_train, y_regression_train, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe0b9d4",
   "metadata": {
    "id": "2fe0b9d4",
    "outputId": "5e2c5afc-20ba-44c0-b3a4-c7417f1d97fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/37 [==============================] - 0s 889us/step\n",
      "41091.38192125212\n",
      "37/37 [==============================] - 0s 917us/step\n",
      "2485492505.8873043\n"
     ]
    }
   ],
   "source": [
    "# оцениваем качество с помощью метрик\n",
    "print(mean_absolute_error(y_regression_test, model_regression.predict(X_regression_test)))\n",
    "print(mean_squared_error(y_regression_test, model_regression.predict(X_regression_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5399f5ba",
   "metadata": {
    "id": "5399f5ba"
   },
   "source": [
    "Мы получили наглядную демонстрацию важного факта - в некоторых задачах применение нейронных сетей менее целесообразно, чем использование более простых моделей. Но иногда они дают лучшие результаты. Важную роль еще играет подбор архитектуры и параметров."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4838f599",
   "metadata": {
    "id": "4838f599"
   },
   "source": [
    "### Бинарная классификация"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5c0f56",
   "metadata": {
    "id": "9b5c0f56"
   },
   "source": [
    "Нейронная сеть для решения задачи классификации будет очень похожа на ту сеть для регрессии, однако у нее по другому будет организован выходной слой. У нас есть 2 стратегии наполнения выходного слоя нейронами:\n",
    "\n",
    "- при решении задачи бинарной классификации мы можем расположить на выходном слое один нейрон с функцией активации sigmoid (значения от 0 и 1), после чего округлять полученные значения; значение нейрона покажет уверенность сети в предсказании; также мы можем расположить 2 нейрона на выходном слое и применить функцию softmax. Тогда сумма значений нейронов выходного слоя будет 1, а предсказание мы сможем получить определив нейрон с наибольшим значением;\n",
    "- в случае многоклассовой классификации, как правило, на выходном слое располагаются k нейронов (по количеству классов), функция активации - softmax; нейрон с наибольшим значением определяет предсказанный класс."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdc09fe",
   "metadata": {
    "id": "cfdc09fe"
   },
   "source": [
    "У нас задача бинарной классификации, попробуем обе стратегии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66cf4a4",
   "metadata": {
    "id": "a66cf4a4",
    "outputId": "b4c9aa05-6b9f-44e8-8086-03a87f6aa200"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2666b6d8b50>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_classification_1 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(23,)),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.05),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        # сначала используем 1 нейрон и sigmoid\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "# в качестве функции активации используется бинарная  кроссэнтропия\n",
    "model_classification_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss=\"mse\")\n",
    "# verbose=None - не будет логов\n",
    "model_classification_1.fit(X_classification_train, y_classification_train, epochs=25, verbose=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e63257",
   "metadata": {
    "id": "46e63257"
   },
   "source": [
    "Посмотрим, как выглядят предсказания сети."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18172a49",
   "metadata": {
    "id": "18172a49",
    "outputId": "5788d18f-ecc8-44f1-950a-cf5d4445dfdd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_classification_1.predict(X_classification_test, verbose=None)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ef5c89e",
   "metadata": {
    "id": "8ef5c89e"
   },
   "source": [
    "Это числа от 0 до 1, поскольку мы использовали sigmoid. Для того, чтобы получить финальное предсказания классов, необходимо округлить все полученные значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161a4c98",
   "metadata": {
    "id": "161a4c98",
    "outputId": "3fcfcaa3-650b-431c-d32b-d5626fa9ee0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      1.00      0.91      1701\n",
      "           1       0.00      0.00      0.00       325\n",
      "\n",
      "    accuracy                           0.84      2026\n",
      "   macro avg       0.42      0.50      0.46      2026\n",
      "weighted avg       0.70      0.84      0.77      2026\n",
      "\n",
      "[[1701    0]\n",
      " [ 325    0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programs\\Python\\ml-labs\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Programs\\Python\\ml-labs\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\Programs\\Python\\ml-labs\\venv\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.around(model_classification_1.predict(X_classification_test, verbose=None))\n",
    "print(classification_report(y_classification_test, y_pred))\n",
    "print(confusion_matrix(y_classification_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048b27da",
   "metadata": {
    "id": "048b27da"
   },
   "source": [
    "Обратите внимание, что дисбаланс классов может привести к неудовлетворительным результатам обучения модели. Необходимо сбалансировать обучающую выборку."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bc4e63",
   "metadata": {
    "id": "43bc4e63"
   },
   "source": [
    "Но, даже без выполнения балансировки, можно взвесить функцию потерь. Можем указать веса (параметр class_weight), которые будут использоваться при оптимизации функции ошибки. В качестве весов классов можно задать величины, обратные количеству элементов класса."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df16179e",
   "metadata": {
    "id": "df16179e"
   },
   "outputs": [],
   "source": [
    "w0 = 1 / y_classification_train[y_classification_train==0].shape[0]\n",
    "w1 = 1 / y_classification_train[y_classification_train==1].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efce734",
   "metadata": {
    "id": "1efce734",
    "outputId": "afe7e5f2-f0c2-45a3-f63b-7c61208df0c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.78      0.85      1701\n",
      "           1       0.38      0.71      0.50       325\n",
      "\n",
      "    accuracy                           0.77      2026\n",
      "   macro avg       0.66      0.75      0.67      2026\n",
      "weighted avg       0.85      0.77      0.79      2026\n",
      "\n",
      "[[1329  372]\n",
      " [  94  231]]\n"
     ]
    }
   ],
   "source": [
    "model_classification_1 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(23,)),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.05),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        # используем 1 нейрон и sigmoid\n",
    "        tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model_classification_1.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss=\"binary_crossentropy\")\n",
    "model_classification_1.fit(X_classification_train, y_classification_train, epochs=25, verbose=None,\n",
    "                           class_weight={0: w0, 1: w1})\n",
    "y_pred = np.around(model_classification_1.predict(X_classification_test, verbose=None))\n",
    "print(classification_report(y_classification_test, y_pred))\n",
    "print(confusion_matrix(y_classification_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370e3660",
   "metadata": {
    "id": "370e3660"
   },
   "source": [
    "Видим улучшения. Можем поиграть с архитектурой и параметрами и добиться еще более качественных результатов. Но напоследок давайте попробуем разместить 2 нейрона на выходном слое и использовать softmax в качестве функции активации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd17e1c4",
   "metadata": {
    "id": "cd17e1c4",
    "outputId": "56b71377-8862-48d7-d8fb-4829c6ca224c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26672245a00>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_classification_2 = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\", input_shape=(23,)),\n",
    "        tf.keras.layers.Dense(128, activation=\"relu\"),\n",
    "        tf.keras.layers.Dropout(0.05),\n",
    "        tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(32, activation=\"relu\"),\n",
    "        tf.keras.layers.Dense(16, activation=\"relu\"),\n",
    "        # сначала используем 2 нейрона и softmax\n",
    "        tf.keras.layers.Dense(2, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "# в качестве функции активации используется категориальная кроссэнтропия\n",
    "# используем разряженный (sparse) вариант, поскольку значения целевого признака не закодированы One-Hot кодированием\n",
    "model_classification_2.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss=\"sparse_categorical_crossentropy\")\n",
    "model_classification_2.fit(X_classification_train, y_classification_train, epochs=25, verbose=None,\n",
    "                           class_weight={0: w0, 1: w1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b44a42",
   "metadata": {
    "id": "34b44a42",
    "outputId": "d34e5d71-0e72-4ab9-ca6c-1af9d6826d73"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.48673633, 0.51326376],\n",
       "       [0.76047015, 0.23952979],\n",
       "       [0.90106165, 0.09893838],\n",
       "       [0.19694562, 0.8030544 ],\n",
       "       [0.19694562, 0.8030544 ]], dtype=float32)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_classification_2.predict(X_classification_test, verbose=None)[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f88855",
   "metadata": {
    "id": "c2f88855"
   },
   "source": [
    "Каждое предсказание - это два числа (потому что два нейрона). Сумма значений равна 1. Каждое значение можно интерпретировать как вероятность отнесения объекта к соответствующему классу (0 или 1). Воспользуемся функцией argmax для того, чтобы получить итоговые предсказания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2143a1ef",
   "metadata": {
    "id": "2143a1ef"
   },
   "outputs": [],
   "source": [
    "# получим индексы максимального значения для каждого элемента (вложенный массив) с помощью numpy\n",
    "y_pred = [np.argmax(pred) for pred in model_classification_2.predict(X_classification_test, verbose=None)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87091ba5",
   "metadata": {
    "id": "87091ba5",
    "outputId": "4ed37b0f-dc35-4c5a-ab0b-51bee6776817"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.78      0.85      1701\n",
      "           1       0.39      0.73      0.50       325\n",
      "\n",
      "    accuracy                           0.77      2026\n",
      "   macro avg       0.66      0.75      0.68      2026\n",
      "weighted avg       0.85      0.77      0.80      2026\n",
      "\n",
      "[[1326  375]\n",
      " [  89  236]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_classification_test, y_pred))\n",
    "print(confusion_matrix(y_classification_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2469c34e",
   "metadata": {
    "id": "2469c34e"
   },
   "source": [
    "Когда мы закончили обучение моделей, мы можем сохранить их на диск, чтобы в будущем либо продолжить обучение (если оно занимает много времени) или использовать для получения предсказаний."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0ea2e8",
   "metadata": {
    "id": "5a0ea2e8",
    "outputId": "67fdc99e-ce2c-4a6d-b174-2e324a94270c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/RegressionModel\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/RegressionModel\\assets\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ClassificationModel1\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ClassificationModel1\\assets\n",
      "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ClassificationModel2\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/ClassificationModel2\\assets\n"
     ]
    }
   ],
   "source": [
    "model_regression.save('../models/RegressionModel')\n",
    "model_classification_1.save('../models/ClassificationModel1')\n",
    "model_classification_2.save('../models/ClassificationModel2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29fc0974",
   "metadata": {
    "id": "29fc0974"
   },
   "source": [
    "Модели сохранены в виде папки. Теперь, когда они нам потребуются, можем очень просто их загрузить. Загрузим, например, модель для регрессии."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cefa072",
   "metadata": {
    "id": "2cefa072",
    "outputId": "2696f2a6-5c3c-47ea-a885-e7a5f4877500"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 64)                2624      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,249\n",
      "Trainable params: 5,249\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_regression_restored = tf.keras.models.load_model('../models/RegressionModel')\n",
    "model_regression_restored.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c837c5",
   "metadata": {
    "id": "58c837c5",
    "outputId": "2f11651c-6436-4423-f520-322df13da4e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41091.38192125212\n",
      "2485492505.8873043\n"
     ]
    }
   ],
   "source": [
    "# используем модель\n",
    "print(mean_absolute_error(y_regression_test, model_regression_restored.predict(X_regression_test, verbose=None)))\n",
    "print(mean_squared_error(y_regression_test, model_regression_restored.predict(X_regression_test, verbose=None)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gW-NhwXEChTS",
   "metadata": {
    "id": "gW-NhwXEChTS"
   },
   "source": [
    "# Задание"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "-IPcUj1UCeIz",
   "metadata": {
    "id": "-IPcUj1UCeIz"
   },
   "source": [
    "<b>Традиционное предупреждение для всех лабораторных работ:</b> перед обучением моделей необходимо выполнить предварительную обработку данных, которая <b>обязательно</b> включает в себя:\n",
    "- заполнение пропущенных значений (рекомедуется логика заполнения пропусков на основе типа данных, которая использовалась в РГР по Практикуму);\n",
    "- преобразование категориальных признаков в числовые (используйте one-hot кодирование или map; используйте знания с Практикума)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jcfIwITzCgTb",
   "metadata": {
    "id": "jcfIwITzCgTb"
   },
   "source": [
    "Предобработка может включать в себя другие действия, но выполнение описанных выше действий обязательно."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "H8y4nWluCkgr",
   "metadata": {
    "id": "H8y4nWluCkgr"
   },
   "source": [
    "Сделайте это один раз и сохраните в отдельный csv файл, а потом его используйте."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "T24SZSN1CmBL",
   "metadata": {
    "id": "T24SZSN1CmBL"
   },
   "source": [
    "<b>Выполните следующие задания:</b>\n",
    "- решите задачи регрессии и классификации на ваших данных используя полносвязные нейронные сети; соберите их используя API Keras фреймворка TensorFlow; оцените качество полученных моделей с помощью метрик; \n",
    "- реализуйте многослойный персептрон, с помощью которого можно решать задачи регрессии и классификации; предусмотрите возможность использовать такие функции активации, как sigmoid, tanh и relu; также предусмотрите возможность указать, сколько слоев нужно, сколько на каждом из них нейронов и какую функцию активации должен иметь слой; реализуйте обучение персептрона методом обратного распространения ошибки; самостоятельно найдите производные функций sigmoid, tanh и relu; реализуйте классический градиентный спуск с возможностью указания шага.\n",
    "\n",
    "<b>Дополнительные задания:</b>\n",
    "- самостоятельно изучите отличия работы оптимизаторов Adam и RMSProp от классического градиентного спуска; реализуйте градиентный спуск с использованием указанных оптимизаторов; предусмотрите возможность использования реализованных вами оптимизаторов в вашем персептроне."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95b67dc",
   "metadata": {
    "id": "ozjLqw6KCoSK"
   },
   "source": [
    "# Задача регресии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "218eef02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3b787849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>221900.0</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1180</td>\n",
       "      <td>5650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1180</td>\n",
       "      <td>0</td>\n",
       "      <td>1955</td>\n",
       "      <td>0</td>\n",
       "      <td>98178</td>\n",
       "      <td>47.5112</td>\n",
       "      <td>-122.257</td>\n",
       "      <td>1340</td>\n",
       "      <td>5650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>538000.0</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2570</td>\n",
       "      <td>7242</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>2170</td>\n",
       "      <td>400</td>\n",
       "      <td>1951</td>\n",
       "      <td>1991</td>\n",
       "      <td>98125</td>\n",
       "      <td>47.7210</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1690</td>\n",
       "      <td>7639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>180000.0</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>2</td>\n",
       "      <td>1.00</td>\n",
       "      <td>770</td>\n",
       "      <td>10000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>770</td>\n",
       "      <td>0</td>\n",
       "      <td>1933</td>\n",
       "      <td>0</td>\n",
       "      <td>98028</td>\n",
       "      <td>47.7379</td>\n",
       "      <td>-122.233</td>\n",
       "      <td>2720</td>\n",
       "      <td>8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>604000.0</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>2014</td>\n",
       "      <td>4</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1960</td>\n",
       "      <td>5000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1050</td>\n",
       "      <td>910</td>\n",
       "      <td>1965</td>\n",
       "      <td>0</td>\n",
       "      <td>98136</td>\n",
       "      <td>47.5208</td>\n",
       "      <td>-122.393</td>\n",
       "      <td>1360</td>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>510000.0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1680</td>\n",
       "      <td>8080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1680</td>\n",
       "      <td>0</td>\n",
       "      <td>1987</td>\n",
       "      <td>0</td>\n",
       "      <td>98074</td>\n",
       "      <td>47.6168</td>\n",
       "      <td>-122.045</td>\n",
       "      <td>1800</td>\n",
       "      <td>7503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21608</th>\n",
       "      <td>360000.0</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>2014</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1530</td>\n",
       "      <td>1131</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1530</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98103</td>\n",
       "      <td>47.6993</td>\n",
       "      <td>-122.346</td>\n",
       "      <td>1530</td>\n",
       "      <td>1509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21609</th>\n",
       "      <td>400000.0</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>2015</td>\n",
       "      <td>4</td>\n",
       "      <td>2.50</td>\n",
       "      <td>2310</td>\n",
       "      <td>5813</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>2310</td>\n",
       "      <td>0</td>\n",
       "      <td>2014</td>\n",
       "      <td>0</td>\n",
       "      <td>98146</td>\n",
       "      <td>47.5107</td>\n",
       "      <td>-122.362</td>\n",
       "      <td>1830</td>\n",
       "      <td>7200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21610</th>\n",
       "      <td>402101.0</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1350</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2009</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5944</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>2007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21611</th>\n",
       "      <td>400000.0</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2015</td>\n",
       "      <td>3</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1600</td>\n",
       "      <td>2388</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1600</td>\n",
       "      <td>0</td>\n",
       "      <td>2004</td>\n",
       "      <td>0</td>\n",
       "      <td>98027</td>\n",
       "      <td>47.5345</td>\n",
       "      <td>-122.069</td>\n",
       "      <td>1410</td>\n",
       "      <td>1287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21612</th>\n",
       "      <td>325000.0</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1020</td>\n",
       "      <td>1076</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1020</td>\n",
       "      <td>0</td>\n",
       "      <td>2008</td>\n",
       "      <td>0</td>\n",
       "      <td>98144</td>\n",
       "      <td>47.5941</td>\n",
       "      <td>-122.299</td>\n",
       "      <td>1020</td>\n",
       "      <td>1357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21613 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          price  day  month  year  bedrooms  bathrooms  sqft_living  sqft_lot  \\\n",
       "0      221900.0   13     10  2014         3       1.00         1180      5650   \n",
       "1      538000.0    9     12  2014         3       2.25         2570      7242   \n",
       "2      180000.0   25      2  2015         2       1.00          770     10000   \n",
       "3      604000.0    9     12  2014         4       3.00         1960      5000   \n",
       "4      510000.0   18      2  2015         3       2.00         1680      8080   \n",
       "...         ...  ...    ...   ...       ...        ...          ...       ...   \n",
       "21608  360000.0   21      5  2014         3       2.50         1530      1131   \n",
       "21609  400000.0   23      2  2015         4       2.50         2310      5813   \n",
       "21610  402101.0   23      6  2014         2       0.75         1020      1350   \n",
       "21611  400000.0   16      1  2015         3       2.50         1600      2388   \n",
       "21612  325000.0   15     10  2014         2       0.75         1020      1076   \n",
       "\n",
       "       floors  waterfront  ...  grade  sqft_above  sqft_basement  yr_built  \\\n",
       "0         1.0           0  ...      7        1180              0      1955   \n",
       "1         2.0           0  ...      7        2170            400      1951   \n",
       "2         1.0           0  ...      6         770              0      1933   \n",
       "3         1.0           0  ...      7        1050            910      1965   \n",
       "4         1.0           0  ...      8        1680              0      1987   \n",
       "...       ...         ...  ...    ...         ...            ...       ...   \n",
       "21608     3.0           0  ...      8        1530              0      2009   \n",
       "21609     2.0           0  ...      8        2310              0      2014   \n",
       "21610     2.0           0  ...      7        1020              0      2009   \n",
       "21611     2.0           0  ...      8        1600              0      2004   \n",
       "21612     2.0           0  ...      7        1020              0      2008   \n",
       "\n",
       "       yr_renovated  zipcode      lat     long  sqft_living15  sqft_lot15  \n",
       "0                 0    98178  47.5112 -122.257           1340        5650  \n",
       "1              1991    98125  47.7210 -122.319           1690        7639  \n",
       "2                 0    98028  47.7379 -122.233           2720        8062  \n",
       "3                 0    98136  47.5208 -122.393           1360        5000  \n",
       "4                 0    98074  47.6168 -122.045           1800        7503  \n",
       "...             ...      ...      ...      ...            ...         ...  \n",
       "21608             0    98103  47.6993 -122.346           1530        1509  \n",
       "21609             0    98146  47.5107 -122.362           1830        7200  \n",
       "21610             0    98144  47.5944 -122.299           1020        2007  \n",
       "21611             0    98027  47.5345 -122.069           1410        1287  \n",
       "21612             0    98144  47.5941 -122.299           1020        1357  \n",
       "\n",
       "[21613 rows x 22 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_regress = pd.read_csv('../data/pre_kc_house_data.csv')\n",
    "data_regress.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "data_regress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e109c73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_regress = data_regress.drop(['price'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "87f26691",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_regress = data_regress['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7db9a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "66deff70",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_regress, X_test_regress,  y_train_regress, y_test_regress = train_test_split(X_regress, y_regress, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df411005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aaf70bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_regress = scaler.fit_transform(X_train_regress)\n",
    "X_test_regress = scaler.transform(X_test_regress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66fb0727",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11b7d5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b00b7d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_regression = Sequential(\n",
    "    [\n",
    "        Dense(64, activation=\"relu\", input_shape=(X_train_regress.shape[1],)),\n",
    "        Dense(32, activation=\"linear\"),\n",
    "        Dropout(0.1),\n",
    "        Dense(16, activation=\"relu\"),\n",
    "        Dropout(0.1),\n",
    "        Dense(1, activation=\"linear\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2bf9ac1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_12 (Dense)            (None, 64)                1408      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_15 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,033\n",
      "Trainable params: 4,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_regression.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ddc52051",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_regression.compile(optimizer=Adam(learning_rate=0.005), loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5ad777f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 172521111552.0000\n",
      "Epoch 2/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 49192337408.0000\n",
      "Epoch 3/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 42314084352.0000\n",
      "Epoch 4/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 41329967104.0000\n",
      "Epoch 5/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 40333164544.0000\n",
      "Epoch 6/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 39052443648.0000\n",
      "Epoch 7/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 39320875008.0000\n",
      "Epoch 8/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 38819991552.0000\n",
      "Epoch 9/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 38638559232.0000\n",
      "Epoch 10/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 39607504896.0000\n",
      "Epoch 11/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 37594640384.0000\n",
      "Epoch 12/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 37091778560.0000\n",
      "Epoch 13/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 37929775104.0000\n",
      "Epoch 14/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 36015804416.0000\n",
      "Epoch 15/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 37784584192.0000\n",
      "Epoch 16/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 36323430400.0000\n",
      "Epoch 17/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 37467906048.0000\n",
      "Epoch 18/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 35298406400.0000\n",
      "Epoch 19/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 36515897344.0000\n",
      "Epoch 20/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 37307392000.0000\n",
      "Epoch 21/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 35398250496.0000\n",
      "Epoch 22/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 36254306304.0000\n",
      "Epoch 23/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 37006618624.0000\n",
      "Epoch 24/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 37175132160.0000\n",
      "Epoch 25/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 36192837632.0000\n",
      "Epoch 26/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 36036730880.0000\n",
      "Epoch 27/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 35044663296.0000\n",
      "Epoch 28/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 35890225152.0000\n",
      "Epoch 29/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 35777974272.0000\n",
      "Epoch 30/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 34143240192.0000\n",
      "Epoch 31/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 33280421888.0000\n",
      "Epoch 32/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 33211351040.0000\n",
      "Epoch 33/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 33659174912.0000\n",
      "Epoch 34/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 33426944000.0000\n",
      "Epoch 35/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 33344593920.0000\n",
      "Epoch 36/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 32085440512.0000\n",
      "Epoch 37/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 32913555456.0000\n",
      "Epoch 38/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 33145098240.0000\n",
      "Epoch 39/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 32892639232.0000\n",
      "Epoch 40/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 32373477376.0000\n",
      "Epoch 41/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 31033550848.0000\n",
      "Epoch 42/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 31855185920.0000\n",
      "Epoch 43/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 32043116544.0000\n",
      "Epoch 44/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 32263168000.0000\n",
      "Epoch 45/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 31961704448.0000\n",
      "Epoch 46/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 31731546112.0000\n",
      "Epoch 47/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 32433383424.0000\n",
      "Epoch 48/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 31454009344.0000\n",
      "Epoch 49/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 31986337792.0000\n",
      "Epoch 50/50\n",
      "541/541 [==============================] - 2s 3ms/step - loss: 31125606400.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x255d14cbb50>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_regression.fit(X_train_regress, y_train_regress, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "afc396c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "136/136 [==============================] - 0s 2ms/step\n",
      "97571.59924748438\n",
      "136/136 [==============================] - 0s 2ms/step\n",
      "25246297833.14532\n"
     ]
    }
   ],
   "source": [
    "print(mean_absolute_error(y_test_regress, model_regression.predict(X_test_regress)))\n",
    "print(mean_squared_error(y_test_regress, model_regression.predict(X_test_regress)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79ef77a",
   "metadata": {},
   "source": [
    "# Задача классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26973370",
   "metadata": {},
   "source": [
    "### для ргр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84819e0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.377995</td>\n",
       "      <td>0.155206</td>\n",
       "      <td>-0.507410</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.346242</td>\n",
       "      <td>-0.201807</td>\n",
       "      <td>-0.730339</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.344031</td>\n",
       "      <td>0.025102</td>\n",
       "      <td>-0.156792</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.392158</td>\n",
       "      <td>-0.222599</td>\n",
       "      <td>0.138186</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.384379</td>\n",
       "      <td>-0.197035</td>\n",
       "      <td>1.184226</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174801</th>\n",
       "      <td>-0.384734</td>\n",
       "      <td>0.076984</td>\n",
       "      <td>-0.501225</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174802</th>\n",
       "      <td>0.805875</td>\n",
       "      <td>-0.198069</td>\n",
       "      <td>-0.677156</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174803</th>\n",
       "      <td>-0.175663</td>\n",
       "      <td>-0.212807</td>\n",
       "      <td>1.263701</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174804</th>\n",
       "      <td>-0.384208</td>\n",
       "      <td>-0.207714</td>\n",
       "      <td>-0.640147</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174805</th>\n",
       "      <td>-0.406324</td>\n",
       "      <td>1.377207</td>\n",
       "      <td>3.154989</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174806 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        distance_from_home  distance_from_last_transaction  \\\n",
       "0                -0.377995                        0.155206   \n",
       "1                -0.346242                       -0.201807   \n",
       "2                -0.344031                        0.025102   \n",
       "3                -0.392158                       -0.222599   \n",
       "4                -0.384379                       -0.197035   \n",
       "...                    ...                             ...   \n",
       "174801           -0.384734                        0.076984   \n",
       "174802            0.805875                       -0.198069   \n",
       "174803           -0.175663                       -0.212807   \n",
       "174804           -0.384208                       -0.207714   \n",
       "174805           -0.406324                        1.377207   \n",
       "\n",
       "        ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "0                            -0.507410                1          0   \n",
       "1                            -0.730339                1          1   \n",
       "2                            -0.156792                1          0   \n",
       "3                             0.138186                1          0   \n",
       "4                             1.184226                1          1   \n",
       "...                                ...              ...        ...   \n",
       "174801                       -0.501225                1          0   \n",
       "174802                       -0.677156                1          1   \n",
       "174803                        1.263701                1          1   \n",
       "174804                       -0.640147                1          0   \n",
       "174805                        3.154989                0          1   \n",
       "\n",
       "        used_pin_number  online_order  fraud  \n",
       "0                     0             1      0  \n",
       "1                     0             1      0  \n",
       "2                     0             1      0  \n",
       "3                     0             1      1  \n",
       "4                     0             1      1  \n",
       "...                 ...           ...    ...  \n",
       "174801                0             0      0  \n",
       "174802                0             1      0  \n",
       "174803                0             1      1  \n",
       "174804                1             1      0  \n",
       "174805                0             0      1  \n",
       "\n",
       "[174806 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_class = pd.read_csv('../data/pred_card_transdata.csv')\n",
    "data_class.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "data_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4704b7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_class = data_class.drop(['fraud'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f939c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_class = data_class['fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f03167c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X_class, y_class, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e518d7db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "4371/4371 [==============================] - 17s 3ms/step - loss: 0.0420\n",
      "Epoch 2/25\n",
      "4371/4371 [==============================] - 15s 3ms/step - loss: 0.0226\n",
      "Epoch 3/25\n",
      "4371/4371 [==============================] - 15s 3ms/step - loss: 0.0174\n",
      "Epoch 4/25\n",
      "4371/4371 [==============================] - 15s 3ms/step - loss: 0.0146\n",
      "Epoch 5/25\n",
      "4371/4371 [==============================] - 15s 3ms/step - loss: 0.0167\n",
      "Epoch 6/25\n",
      "4371/4371 [==============================] - 15s 3ms/step - loss: 0.0130\n",
      "Epoch 7/25\n",
      "4371/4371 [==============================] - 15s 4ms/step - loss: 0.0122\n",
      "Epoch 8/25\n",
      "4371/4371 [==============================] - 15s 3ms/step - loss: 0.0161\n",
      "Epoch 9/25\n",
      "4371/4371 [==============================] - 15s 3ms/step - loss: 0.0145\n",
      "Epoch 10/25\n",
      "4371/4371 [==============================] - 15s 3ms/step - loss: 0.0136\n",
      "Epoch 11/25\n",
      "4371/4371 [==============================] - 15s 3ms/step - loss: 0.0111\n",
      "Epoch 12/25\n",
      "4371/4371 [==============================] - 15s 3ms/step - loss: 0.0115\n",
      "Epoch 13/25\n",
      "4371/4371 [==============================] - 15s 3ms/step - loss: 0.0104\n",
      "Epoch 14/25\n",
      "4371/4371 [==============================] - 15s 3ms/step - loss: 0.0168\n",
      "Epoch 15/25\n",
      "4371/4371 [==============================] - 15s 3ms/step - loss: 0.0130\n",
      "Epoch 16/25\n",
      "4371/4371 [==============================] - 15s 3ms/step - loss: 0.0099\n",
      "Epoch 17/25\n",
      "4371/4371 [==============================] - 15s 3ms/step - loss: 0.0149\n",
      "Epoch 18/25\n",
      "4371/4371 [==============================] - 15s 3ms/step - loss: 0.0126\n",
      "Epoch 19/25\n",
      "4371/4371 [==============================] - 15s 3ms/step - loss: 0.0097\n",
      "Epoch 20/25\n",
      "4371/4371 [==============================] - 15s 3ms/step - loss: 0.0244\n",
      "Epoch 21/25\n",
      "4371/4371 [==============================] - 15s 3ms/step - loss: 0.0110\n",
      "Epoch 22/25\n",
      "4371/4371 [==============================] - 15s 3ms/step - loss: 0.0178\n",
      "Epoch 23/25\n",
      "4371/4371 [==============================] - 15s 4ms/step - loss: 0.0116\n",
      "Epoch 24/25\n",
      "4371/4371 [==============================] - 15s 3ms/step - loss: 0.0126\n",
      "Epoch 25/25\n",
      "4371/4371 [==============================] - 15s 3ms/step - loss: 0.0169\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13b8aeb9460>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_classification_1 = Sequential(\n",
    "    [\n",
    "        Dense(64, activation=\"relu\", input_shape=(X_train_class.shape[1],)),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dropout(0.05),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        Dense(16, activation=\"relu\"),\n",
    "        Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model_classification_1.compile(optimizer=Adam(learning_rate=0.005), loss=\"binary_crossentropy\")\n",
    "\n",
    "model_classification_1.fit(X_train_class, y_train_class, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "db9cbf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_classification_1.save('../models/ModelNN_Classifier.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53092ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653bf6a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d80e916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129aea29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cec5199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distance_from_home</th>\n",
       "      <th>distance_from_last_transaction</th>\n",
       "      <th>ratio_to_median_purchase_price</th>\n",
       "      <th>repeat_retailer</th>\n",
       "      <th>used_chip</th>\n",
       "      <th>used_pin_number</th>\n",
       "      <th>online_order</th>\n",
       "      <th>fraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20.211127</td>\n",
       "      <td>0.080074</td>\n",
       "      <td>0.765894</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.991784</td>\n",
       "      <td>1.063091</td>\n",
       "      <td>0.843780</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16.510867</td>\n",
       "      <td>3.927569</td>\n",
       "      <td>0.174174</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.000027</td>\n",
       "      <td>0.231883</td>\n",
       "      <td>1.427570</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18.061769</td>\n",
       "      <td>0.623783</td>\n",
       "      <td>4.331394</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174801</th>\n",
       "      <td>5.912711</td>\n",
       "      <td>0.048860</td>\n",
       "      <td>2.242847</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174802</th>\n",
       "      <td>6.057480</td>\n",
       "      <td>0.339883</td>\n",
       "      <td>0.467084</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174803</th>\n",
       "      <td>10.162044</td>\n",
       "      <td>2.566964</td>\n",
       "      <td>0.857462</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174804</th>\n",
       "      <td>42.822821</td>\n",
       "      <td>0.317691</td>\n",
       "      <td>4.204283</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174805</th>\n",
       "      <td>6.703017</td>\n",
       "      <td>21.583846</td>\n",
       "      <td>0.394601</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>174806 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        distance_from_home  distance_from_last_transaction  \\\n",
       "0                20.211127                        0.080074   \n",
       "1                 3.991784                        1.063091   \n",
       "2                16.510867                        3.927569   \n",
       "3                 2.000027                        0.231883   \n",
       "4                18.061769                        0.623783   \n",
       "...                    ...                             ...   \n",
       "174801            5.912711                        0.048860   \n",
       "174802            6.057480                        0.339883   \n",
       "174803           10.162044                        2.566964   \n",
       "174804           42.822821                        0.317691   \n",
       "174805            6.703017                       21.583846   \n",
       "\n",
       "        ratio_to_median_purchase_price  repeat_retailer  used_chip  \\\n",
       "0                             0.765894              1.0        1.0   \n",
       "1                             0.843780              1.0        0.0   \n",
       "2                             0.174174              1.0        0.0   \n",
       "3                             1.427570              1.0        1.0   \n",
       "4                             4.331394              1.0        0.0   \n",
       "...                                ...              ...        ...   \n",
       "174801                        2.242847              1.0        0.0   \n",
       "174802                        0.467084              1.0        1.0   \n",
       "174803                        0.857462              1.0        1.0   \n",
       "174804                        4.204283              1.0        1.0   \n",
       "174805                        0.394601              1.0        0.0   \n",
       "\n",
       "        used_pin_number  online_order  fraud  \n",
       "0                   0.0           1.0    0.0  \n",
       "1                   0.0           1.0    0.0  \n",
       "2                   0.0           0.0    0.0  \n",
       "3                   0.0           0.0    0.0  \n",
       "4                   0.0           1.0    1.0  \n",
       "...                 ...           ...    ...  \n",
       "174801              0.0           1.0    0.0  \n",
       "174802              1.0           1.0    0.0  \n",
       "174803              0.0           1.0    0.0  \n",
       "174804              0.0           1.0    1.0  \n",
       "174805              0.0           1.0    0.0  \n",
       "\n",
       "[174806 rows x 8 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_class = pd.read_csv('../data/pre_card_transdata.csv')\n",
    "data_class.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "data_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74750f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_class = data_class.drop(['fraud'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6e078dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_class = data_class['fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9578c9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X_class, y_class, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b865784",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_class = scaler.fit_transform(X_train_class)\n",
    "X_test_class = scaler.transform(X_test_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "194902dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "4371/4371 [==============================] - 17s 4ms/step - loss: 0.0415\n",
      "Epoch 2/25\n",
      "4371/4371 [==============================] - 15s 4ms/step - loss: 0.0208\n",
      "Epoch 3/25\n",
      "4371/4371 [==============================] - 16s 4ms/step - loss: 0.0159\n",
      "Epoch 4/25\n",
      "4371/4371 [==============================] - 16s 4ms/step - loss: 0.0175\n",
      "Epoch 5/25\n",
      "4371/4371 [==============================] - 16s 4ms/step - loss: 0.0136\n",
      "Epoch 6/25\n",
      "4371/4371 [==============================] - 16s 4ms/step - loss: 0.0129\n",
      "Epoch 7/25\n",
      "4371/4371 [==============================] - 17s 4ms/step - loss: 0.0143\n",
      "Epoch 8/25\n",
      "4371/4371 [==============================] - 16s 4ms/step - loss: 0.0125\n",
      "Epoch 9/25\n",
      "4371/4371 [==============================] - 16s 4ms/step - loss: 0.0129\n",
      "Epoch 10/25\n",
      "4371/4371 [==============================] - 15s 4ms/step - loss: 0.0145\n",
      "Epoch 11/25\n",
      "4371/4371 [==============================] - 15s 4ms/step - loss: 0.0138\n",
      "Epoch 12/25\n",
      "4371/4371 [==============================] - 15s 4ms/step - loss: 0.0131\n",
      "Epoch 13/25\n",
      "4371/4371 [==============================] - 15s 3ms/step - loss: 0.0105\n",
      "Epoch 14/25\n",
      "4371/4371 [==============================] - 15s 3ms/step - loss: 0.0281\n",
      "Epoch 15/25\n",
      "4371/4371 [==============================] - 16s 4ms/step - loss: 0.0160\n",
      "Epoch 16/25\n",
      "4371/4371 [==============================] - 16s 4ms/step - loss: 0.0146\n",
      "Epoch 17/25\n",
      "4371/4371 [==============================] - 16s 4ms/step - loss: 0.0139\n",
      "Epoch 18/25\n",
      "4371/4371 [==============================] - 16s 4ms/step - loss: 0.0139\n",
      "Epoch 19/25\n",
      "4371/4371 [==============================] - 16s 4ms/step - loss: 0.0680\n",
      "Epoch 20/25\n",
      "4371/4371 [==============================] - 16s 4ms/step - loss: 0.0133\n",
      "Epoch 21/25\n",
      "4371/4371 [==============================] - 16s 4ms/step - loss: 0.0099\n",
      "Epoch 22/25\n",
      "4371/4371 [==============================] - 15s 4ms/step - loss: 0.0146\n",
      "Epoch 23/25\n",
      "4371/4371 [==============================] - 16s 4ms/step - loss: 0.0093\n",
      "Epoch 24/25\n",
      "4371/4371 [==============================] - 16s 4ms/step - loss: 0.0121\n",
      "Epoch 25/25\n",
      "4371/4371 [==============================] - 16s 4ms/step - loss: 0.0137\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2325b832d00>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_classification_1 = Sequential(\n",
    "    [\n",
    "        Dense(64, activation=\"relu\", input_shape=(X_train_class.shape[1],)),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dropout(0.05),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        Dense(16, activation=\"relu\"),\n",
    "        Dense(1, activation=\"sigmoid\"),\n",
    "    ]\n",
    ")\n",
    "model_classification_1.compile(optimizer=Adam(learning_rate=0.005), loss=\"binary_crossentropy\")\n",
    "\n",
    "model_classification_1.fit(X_train_class, y_train_class, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96dfbe2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0feeefe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 2s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      1.00     17528\n",
      "         1.0       0.99      1.00      1.00     17434\n",
      "\n",
      "    accuracy                           1.00     34962\n",
      "   macro avg       1.00      1.00      1.00     34962\n",
      "weighted avg       1.00      1.00      1.00     34962\n",
      "\n",
      "[[17416   112]\n",
      " [   12 17422]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = np.around(model_classification_1.predict(X_test_class))\n",
    "print(classification_report(y_test_class, y_pred))\n",
    "print(confusion_matrix(y_test_class, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b9d49dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../models/NN_Classifier\\assets\n"
     ]
    }
   ],
   "source": [
    "model_classification_1.save('../models/NN_Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "56ccdebe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "4371/4371 [==============================] - 16s 3ms/step - loss: 0.0422\n",
      "Epoch 2/25\n",
      "4371/4371 [==============================] - 15s 3ms/step - loss: 0.0233\n",
      "Epoch 3/25\n",
      "4371/4371 [==============================] - 15s 4ms/step - loss: 0.0203\n",
      "Epoch 4/25\n",
      "4371/4371 [==============================] - 15s 4ms/step - loss: 0.0173\n",
      "Epoch 5/25\n",
      "4371/4371 [==============================] - 16s 4ms/step - loss: 0.0245\n",
      "Epoch 6/25\n",
      "4371/4371 [==============================] - 16s 4ms/step - loss: 0.0204\n",
      "Epoch 7/25\n",
      "4371/4371 [==============================] - 16s 4ms/step - loss: 0.0330\n",
      "Epoch 8/25\n",
      "4371/4371 [==============================] - 16s 4ms/step - loss: 0.0178\n",
      "Epoch 9/25\n",
      "4371/4371 [==============================] - 16s 4ms/step - loss: 0.0544\n",
      "Epoch 10/25\n",
      "4371/4371 [==============================] - 16s 4ms/step - loss: 0.0138\n",
      "Epoch 11/25\n",
      "4371/4371 [==============================] - 16s 4ms/step - loss: 0.0136\n",
      "Epoch 12/25\n",
      "4371/4371 [==============================] - 15s 4ms/step - loss: 0.0213\n",
      "Epoch 13/25\n",
      "4371/4371 [==============================] - 16s 4ms/step - loss: 0.0216\n",
      "Epoch 14/25\n",
      "4371/4371 [==============================] - 15s 4ms/step - loss: 0.0384\n",
      "Epoch 15/25\n",
      "4371/4371 [==============================] - 15s 4ms/step - loss: 0.0305\n",
      "Epoch 16/25\n",
      "4371/4371 [==============================] - 15s 3ms/step - loss: 0.0260\n",
      "Epoch 17/25\n",
      "4371/4371 [==============================] - 15s 3ms/step - loss: 0.0493\n",
      "Epoch 18/25\n",
      "4371/4371 [==============================] - 15s 4ms/step - loss: 0.0519\n",
      "Epoch 19/25\n",
      "4371/4371 [==============================] - 15s 4ms/step - loss: 0.0496\n",
      "Epoch 20/25\n",
      "4371/4371 [==============================] - 15s 3ms/step - loss: 0.0537\n",
      "Epoch 21/25\n",
      "4371/4371 [==============================] - 15s 3ms/step - loss: 0.1179\n",
      "Epoch 22/25\n",
      "4371/4371 [==============================] - 15s 3ms/step - loss: 0.0688\n",
      "Epoch 23/25\n",
      "4371/4371 [==============================] - 15s 3ms/step - loss: 0.0767\n",
      "Epoch 24/25\n",
      "4371/4371 [==============================] - 15s 3ms/step - loss: 0.0923\n",
      "Epoch 25/25\n",
      "4371/4371 [==============================] - 15s 3ms/step - loss: 0.0982\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x255eb782fa0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_classification_2 = tf.keras.Sequential(\n",
    "    [\n",
    "        Dense(64, activation=\"relu\", input_shape=(X_train_class.shape[1],)),\n",
    "        Dense(128, activation=\"relu\"),\n",
    "        Dropout(0.05),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        Dense(16, activation=\"relu\"),\n",
    "        Dense(2, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model_classification_2.compile(optimizer=Adam(learning_rate=0.005), loss=\"sparse_categorical_crossentropy\")\n",
    "model_classification_2.fit(X_train_class, y_train_class, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "424c65fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1093/1093 [==============================] - 2s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = [np.argmax(pred) for pred in model_classification_2.predict(X_test_class)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8eafcb4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.96      0.98     17499\n",
      "         1.0       0.96      0.99      0.98     17463\n",
      "\n",
      "    accuracy                           0.98     34962\n",
      "   macro avg       0.98      0.98      0.98     34962\n",
      "weighted avg       0.98      0.98      0.98     34962\n",
      "\n",
      "[[16869   630]\n",
      " [   96 17367]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_class, y_pred))\n",
    "print(confusion_matrix(y_test_class, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f9c1d5",
   "metadata": {},
   "source": [
    "## Реализация многослойного персептрона"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "2914ded0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_batches(inputs, outputs, batchsize):\n",
    "        l = len(inputs)\n",
    "        for ndx in range(0, l, batchsize):\n",
    "            yield inputs[ndx:min(ndx + batchsize, l)], outputs[ndx:min(ndx + batchsize, l)]\n",
    "\n",
    "class DenseLayer:\n",
    "    def __init__(self, n_units, input_size=None, activation=None):\n",
    "        \n",
    "        self.n_units = n_units                                    \n",
    "        self.input_size = input_size                               \n",
    "        self.W = None                                                                                      \n",
    "        self.A = None                              \n",
    "        self.fn, self.df = self.select_activation_fn(activation)\n",
    "\n",
    "    def select_activation_fn(self, activation):\n",
    "        if activation == 'relu':\n",
    "            fn = lambda x: np.maximum(0, x)\n",
    "            df = lambda x: np.where(x < 0, 0.0, 1.0)\n",
    "        elif activation == 'sigmoid':\n",
    "            fn = lambda x: 1 / (1 + np.exp(-x))\n",
    "            df = lambda x: fn(x) * fn(1 - x)\n",
    "        elif activation == 'tanh':\n",
    "            fn = lambda x: (np.exp(x) - np.exp(-1)) / (np.exp(x) + np.exp(-x))\n",
    "            df = lambda x: 1 / np.cos(x) ** 2\n",
    "        elif activation == 'linear':\n",
    "            fn = lambda x: x\n",
    "            df = lambda x: 1.0\n",
    "        return fn, df\n",
    "\n",
    "    def init_weights(self):\n",
    "        self.W = np.random.randn(self.n_units, self.input_size + 1)\n",
    "    \n",
    "    def get_activation_value(self, X):\n",
    "        m_examples = X.shape[0]\n",
    "        X_new = np.hstack([np.ones((m_examples, 1)), X])\n",
    "        Z = np.dot(X_new, self.W.T)\n",
    "        A = self.fn(Z)\n",
    "        self.A = A\n",
    "        return A\n",
    "    \n",
    "    def backprop(self, delta, a):\n",
    "        da = self.df(a)    \n",
    "        return np.dot(delta, self.W)[:, 1:] * da\n",
    "\n",
    "class SequentialModel:\n",
    "    def __init__(self, layers):     \n",
    "        input_size = layers[0].n_units       \n",
    "        layers[0].init_weights()             \n",
    "        for layer in layers[1:]:             \n",
    "            layer.input_size = input_size\n",
    "            input_size = layer.n_units\n",
    "            layer.init_weights()\n",
    "        self.layers = layers\n",
    "        self.lr = None\n",
    "\n",
    "    def forward(self, X):            \n",
    "        out = self.layers[0].get_activation_value(X)\n",
    "        for layer in self.layers[1:]:\n",
    "            out = layer.get_activation_value(out)\n",
    "        return out\n",
    "    \n",
    "    def add_dim(self, x):\n",
    "        return np.hstack([np.ones((x.shape[0], 1)), x])\n",
    "\n",
    "    def backward(self, X, y_pred, y_true):\n",
    "        n_layers = len(self.layers)\n",
    "        delta = y_pred - y_true\n",
    "        a = y_pred\n",
    "        dWs = {}\n",
    "        for i in range(-1, -len(self.layers), -1):\n",
    "            a = self.layers[i - 1].A       \n",
    "            dWs[i] = np.dot(delta.T, self.add_dim(a))\n",
    "            delta = self.layers[i].backprop(delta, a)\n",
    "\n",
    "        dWs[-n_layers] = np.dot(delta.T, self.add_dim(X))\n",
    "\n",
    "        for k, dW in dWs.items():\n",
    "            self.layers[k].W -= self.lr * dW\n",
    "            \n",
    "    def fit(self, X, y, epochs, batchsize=32, lr=0.01):\n",
    "        \n",
    "        self.lr = lr\n",
    "\n",
    "        for i in range(epochs):\n",
    "\n",
    "            for batch in iterate_batches(X, y, batchsize=batchsize):\n",
    "                \n",
    "                X_batch = batch[0]\n",
    "                y_batch = batch[1]\n",
    "                \n",
    "                if not isinstance(y_batch, np.ndarray):\n",
    "                    y_batch = y_batch.to_numpy()\n",
    "                    \n",
    "                y_batch = y_batch.reshape(-1, 1)\n",
    "                y_pred = model.forward(X_batch)\n",
    "                model.backward(X_batch, y_pred, y_batch)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "873e31c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 1, 1, 0, 1, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "np.random.seed(42)\n",
    "X, y = make_classification(n_samples=10, n_features=4, \n",
    "    n_classes=2)\n",
    "y_true = y.reshape(-1, 1)\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "model = SequentialModel([\n",
    "    DenseLayer(6, activation='sigmoid', input_size= X.shape[1]),\n",
    "    DenseLayer(4, activation='tanh'),\n",
    "    DenseLayer(3, activation='relu'),\n",
    "    DenseLayer(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.fit(X, y, epochs=100, batchsize=2)\n",
    "    \n",
    "display(np.where(model.forward(X)> 0.5, 1, 0), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "9c32d5bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([ -88.67672026,  176.18716008, -115.26173746, -238.8166274 ,\n",
       "       -285.52976996,    3.46029271,  234.57846761, -337.21521568,\n",
       "       -118.70177666,   28.36950144])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "np.random.seed(42)\n",
    "X, y = make_regression(n_samples=10, n_features=4)\n",
    "y_true = y.reshape(-1, 1)\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "model = SequentialModel([\n",
    "    DenseLayer(6, activation='relu', input_size=X.shape[1]),\n",
    "    DenseLayer(4, activation='linear'),\n",
    "    DenseLayer(3, activation='relu'),\n",
    "    DenseLayer(1, activation='linear')\n",
    "])\n",
    "\n",
    "model.fit(X, y, epochs = 100, batchsize=3)\n",
    "    \n",
    "display(model.forward(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "d1fe69d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\savth\\AppData\\Local\\Temp\\ipykernel_10252\\4147269636.py:20: RuntimeWarning: overflow encountered in exp\n",
      "  fn = lambda x: 1 / (1 + np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "data_class = pd.read_csv('../data/pre_card_transdata.csv')\n",
    "data_class.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "\n",
    "X_class = data_class.drop(['fraud'], axis=1)\n",
    "y_class = data_class['fraud']\n",
    "X_train_class, X_test_class, y_train_class, y_test_class = train_test_split(X_class, y_class, test_size=0.2)\n",
    "scaler = StandardScaler()\n",
    "X_train_class = scaler.fit_transform(X_train_class)\n",
    "X_test_class = scaler.transform(X_test_class)\n",
    "\n",
    "model = SequentialModel([\n",
    "    DenseLayer(6, activation='sigmoid', input_size=X_class.shape[1]),\n",
    "    DenseLayer(4, activation='tanh'),\n",
    "    DenseLayer(3, activation='relu'),\n",
    "    DenseLayer(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.fit(X_train_class, y_train_class, epochs = 5, batchsize=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "be07906c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\savth\\AppData\\Local\\Temp\\ipykernel_10252\\4147269636.py:20: RuntimeWarning: overflow encountered in exp\n",
      "  fn = lambda x: 1 / (1 + np.exp(-x))\n"
     ]
    }
   ],
   "source": [
    "pred = model.forward(X_test_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "9ed98506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00126699],\n",
       "       [0.75340473],\n",
       "       [0.75340473],\n",
       "       ...,\n",
       "       [0.00126699],\n",
       "       [0.00126699],\n",
       "       [0.00126699]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "fc55c416",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.where(pred > 0.5, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "967d9079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "f0946fac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_class[:10].astype(int).values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a04173c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.89      0.93     17451\n",
      "         1.0       0.90      0.97      0.93     17511\n",
      "\n",
      "    accuracy                           0.93     34962\n",
      "   macro avg       0.93      0.93      0.93     34962\n",
      "weighted avg       0.93      0.93      0.93     34962\n",
      "\n",
      "[[15507  1944]\n",
      " [  509 17002]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(classification_report(y_test_class, pred))\n",
    "print(confusion_matrix(y_test_class, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "2f60acd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "data_regress = pd.read_csv('../data/pre_kc_house_data.csv')\n",
    "data_regress.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
    "\n",
    "X_regress = data_regress.drop(['price'], axis=1)\n",
    "y_regress = data_regress['price']\n",
    "X_train_regress, X_test_regress, y_train_regress, y_test_regress = train_test_split(X_regress, y_regress, test_size=0.2)\n",
    "scaler = StandardScaler()\n",
    "X_train_regress = scaler.fit_transform(X_train_regress)\n",
    "X_test_regress = scaler.transform(X_test_regress)\n",
    "\n",
    "model = SequentialModel([\n",
    "    DenseLayer(6, activation='relu', input_size=X_regress.shape[1]),\n",
    "    DenseLayer(4, activation='linear'),\n",
    "    DenseLayer(3, activation='relu'),\n",
    "    DenseLayer(1, activation='linear')\n",
    "])\n",
    "\n",
    "model.fit(X_train_regress, y_train_regress, epochs = 10, batchsize=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "61dc8282",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.forward(X_test_regress) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "1eebd2ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[nan],\n",
       "       [nan],\n",
       "       [nan],\n",
       "       ...,\n",
       "       [nan],\n",
       "       [nan],\n",
       "       [nan]])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
